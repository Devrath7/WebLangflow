{"id":"6302081f-5af2-4b9f-bd19-2baaf7218ba6","data":{"nodes":[{"id":"HierarchicalCrewComponent-JNKGT","type":"genericNode","position":{"x":568,"y":352.296875},"data":{"type":"HierarchicalCrewComponent","node":{"template":{"_type":"Component","agents":{"trace_as_metadata":true,"list":true,"required":false,"placeholder":"","show":true,"value":"","name":"agents","display_name":"Agents","advanced":false,"input_types":["Agent"],"dynamic":false,"info":"","title_case":false,"type":"other"},"function_calling_llm":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"function_calling_llm","display_name":"Function Calling LLM","advanced":true,"input_types":["LanguageModel"],"dynamic":false,"info":"","title_case":false,"type":"other"},"manager_agent":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"manager_agent","display_name":"Manager Agent","advanced":false,"input_types":["Agent"],"dynamic":false,"info":"","title_case":false,"type":"other"},"manager_llm":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"manager_llm","display_name":"Manager LLM","advanced":false,"input_types":["LanguageModel"],"dynamic":false,"info":"","title_case":false,"type":"other"},"tasks":{"trace_as_metadata":true,"list":true,"required":false,"placeholder":"","show":true,"value":"","name":"tasks","display_name":"Tasks","advanced":false,"input_types":["HierarchicalTask"],"dynamic":false,"info":"","title_case":false,"type":"other"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from crewai import Crew, Process  # type: ignore\n\nfrom langflow.base.agents.crewai.crew import BaseCrewComponent\nfrom langflow.io import HandleInput\n\n\nclass HierarchicalCrewComponent(BaseCrewComponent):\n    display_name: str = \"Hierarchical Crew\"\n    description: str = (\n        \"Represents a group of agents, defining how they should collaborate and the tasks they should perform.\"\n    )\n\n    inputs = BaseCrewComponent._base_inputs + [\n        HandleInput(name=\"agents\", display_name=\"Agents\", input_types=[\"Agent\"], is_list=True),\n        HandleInput(name=\"tasks\", display_name=\"Tasks\", input_types=[\"HierarchicalTask\"], is_list=True),\n        HandleInput(name=\"manager_llm\", display_name=\"Manager LLM\", input_types=[\"LanguageModel\"], required=False),\n        HandleInput(name=\"manager_agent\", display_name=\"Manager Agent\", input_types=[\"Agent\"], required=False),\n    ]\n\n    def build_crew(self) -> Crew:\n        tasks, agents = self.get_tasks_and_agents()\n        crew = Crew(\n            agents=agents,\n            tasks=tasks,\n            process=Process.hierarchical,\n            verbose=self.verbose,\n            memory=self.memory,\n            cache=self.use_cache,\n            max_rpm=self.max_rpm,\n            share_crew=self.share_crew,\n            function_calling_llm=self.function_calling_llm,\n            manager_agent=self.manager_agent,\n            manager_llm=self.manager_llm,\n            step_callback=self.get_step_callback(),\n            task_callback=self.get_task_callback(),\n        )\n        return crew\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"max_rpm":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":100,"name":"max_rpm","display_name":"Max RPM","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"int"},"memory":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"memory","display_name":"Memory","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool"},"share_crew":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"share_crew","display_name":"Share Crew","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool"},"use_cache":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":true,"name":"use_cache","display_name":"Cache","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool"},"verbose":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":0,"name":"verbose","display_name":"Verbose","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"int"}},"description":"Represents a group of agents, defining how they should collaborate and the tasks they should perform.","icon":"CrewAI","base_classes":["Message"],"display_name":"Hierarchical Crew","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"output","display_name":"Output","method":"build_output","value":"__UNDEFINED__","cache":true}],"field_order":["verbose","memory","use_cache","max_rpm","share_crew","function_calling_llm","agents","tasks","manager_llm","manager_agent"],"beta":false,"edited":false},"id":"HierarchicalCrewComponent-JNKGT","description":"Represents a group of agents, defining how they should collaborate and the tasks they should perform.","display_name":"Hierarchical Crew"},"selected":false,"width":384,"height":459,"dragging":false},{"id":"OpenAIModel-xoZ41","type":"genericNode","position":{"x":-1222.8457213471152,"y":696.8902718289911},"data":{"type":"OpenAIModel","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"json_mode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"json_mode","display_name":"JSON Mode","advanced":true,"dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","title_case":false,"type":"bool"},"max_tokens":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int"},"model_kwargs":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":{},"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"dict"},"model_name":{"trace_as_metadata":true,"options":["gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"required":false,"placeholder":"","show":true,"value":"gpt-4o","name":"model_name","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str"},"openai_api_base":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"openai_api_base","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","title_case":false,"type":"str"},"openai_api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"value":"","name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"input_types":[],"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","title_case":false,"password":true,"type":"str"},"output_schema":{"trace_as_input":true,"list":true,"required":false,"placeholder":"","show":true,"value":{},"name":"output_schema","display_name":"Schema","advanced":true,"dynamic":false,"info":"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.","title_case":false,"type":"dict"},"seed":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":1,"name":"seed","display_name":"Seed","advanced":true,"dynamic":false,"info":"The seed controls the reproducibility of the job.","title_case":false,"type":"int"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool"},"system_message":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":0.1,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float"}},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["LanguageModel","Message"],"display_name":"OpenAI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","max_tokens","model_kwargs","json_mode","output_schema","model_name","openai_api_base","openai_api_key","temperature","stream","system_message","seed"],"beta":false,"edited":false},"id":"OpenAIModel-xoZ41"},"selected":false,"width":384,"height":623,"positionAbsolute":{"x":-1222.8457213471152,"y":696.8902718289911},"dragging":false},{"id":"ChatOutput-IACYe","type":"genericNode","position":{"x":1070.9148596889393,"y":499.80777483894144},"data":{"type":"ChatOutput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.memory import store_message\nfrom langflow.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"data_template":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"{text}","name":"data_template","display_name":"Data Template","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.","title_case":false,"type":"str"},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Message to be passed as output.","title_case":false,"type":"str"},"sender":{"trace_as_metadata":true,"options":["Machine","User"],"required":false,"placeholder":"","show":true,"value":"Machine","name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"Type of sender.","title_case":false,"type":"str"},"sender_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"AI","name":"sender_name","display_name":"Sender Name","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Name of the sender.","title_case":false,"type":"str"},"session_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"session_id","display_name":"Session ID","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Session ID for the message.","title_case":false,"type":"str"},"should_store_message":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":true,"name":"should_store_message","display_name":"Store Messages","advanced":true,"dynamic":false,"info":"Store the message in the history.","title_case":false,"type":"bool"}},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["Message"],"display_name":"Chat Output","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"message","display_name":"Message","method":"message_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","should_store_message","sender","sender_name","session_id","data_template"],"beta":false,"edited":false},"id":"ChatOutput-IACYe","description":"Display a chat message in the Playground.","display_name":"Chat Output"},"selected":false,"width":384,"height":309,"positionAbsolute":{"x":1070.9148596889393,"y":499.80777483894144},"dragging":false},{"id":"HierarchicalTaskComponent-vvJXu","type":"genericNode","position":{"x":63.673086094601445,"y":-402.645235449293},"data":{"type":"HierarchicalTaskComponent","node":{"template":{"_type":"Component","tools":{"trace_as_metadata":true,"list":true,"required":false,"placeholder":"","show":true,"value":"","name":"tools","display_name":"Tools","advanced":true,"input_types":["Tool"],"dynamic":false,"info":"List of tools/resources limited for task execution. Uses the Agent tools by default.","title_case":false,"type":"other"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.agents.crewai.tasks import HierarchicalTask\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, MultilineInput, Output\n\n\nclass HierarchicalTaskComponent(Component):\n    display_name: str = \"Hierarchical Task\"\n    description: str = \"Each task must have a description, an expected output and an agent responsible for execution.\"\n    icon = \"CrewAI\"\n    inputs = [\n        MultilineInput(\n            name=\"task_description\",\n            display_name=\"Description\",\n            info=\"Descriptive text detailing task's purpose and execution.\",\n        ),\n        MultilineInput(\n            name=\"expected_output\",\n            display_name=\"Expected Output\",\n            info=\"Clear definition of expected task outcome.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"List of tools/resources limited for task execution. Uses the Agent tools by default.\",\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Task\", name=\"task_output\", method=\"build_task\"),\n    ]\n\n    def build_task(self) -> HierarchicalTask:\n        task = HierarchicalTask(\n            description=self.task_description,\n            expected_output=self.expected_output,\n            tools=self.tools or [],\n        )\n        self.status = task\n        return task\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"expected_output":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"expected_output","display_name":"Expected Output","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Clear definition of expected task outcome.","title_case":false,"type":"str"},"task_description":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"task_description","display_name":"Description","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Descriptive text detailing task's purpose and execution.","title_case":false,"type":"str"}},"description":"Each task must have a description, an expected output and an agent responsible for execution.","icon":"CrewAI","base_classes":["HierarchicalTask"],"display_name":"Hierarchical Task","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["HierarchicalTask"],"selected":"HierarchicalTask","name":"task_output","display_name":"Task","method":"build_task","value":"__UNDEFINED__","cache":true}],"field_order":["task_description","expected_output","tools"],"beta":false,"edited":false},"id":"HierarchicalTaskComponent-vvJXu","description":"Each task must have a description, an expected output and an agent responsible for execution.","display_name":"Hierarchical Task"},"selected":true,"width":384,"height":455,"positionAbsolute":{"x":63.673086094601445,"y":-402.645235449293},"dragging":false},{"id":"CrewAIAgentComponent-XU5MB","type":"genericNode","position":{"x":-458.5916982102759,"y":446.46227931983833},"data":{"type":"CrewAIAgentComponent","node":{"template":{"_type":"Component","llm":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"llm","display_name":"Language Model","advanced":false,"input_types":["LanguageModel"],"dynamic":false,"info":"Language model that will run the agent.","title_case":false,"type":"other"},"tools":{"trace_as_metadata":true,"list":true,"required":false,"placeholder":"","show":true,"value":[],"name":"tools","display_name":"Tools","advanced":false,"input_types":["Tool"],"dynamic":false,"info":"Tools at agents disposal","title_case":false,"type":"other"},"allow_code_execution":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"allow_code_execution","display_name":"Allow Code Execution","advanced":true,"dynamic":false,"info":"Whether the agent is allowed to execute code.","title_case":false,"type":"bool"},"allow_delegation":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":true,"name":"allow_delegation","display_name":"Allow Delegation","advanced":false,"dynamic":false,"info":"Whether the agent is allowed to delegate tasks to other agents.","title_case":false,"type":"bool"},"backstory":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"You are polite and helpful. You've always been a beacon of politeness.","name":"backstory","display_name":"Backstory","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The backstory of the agent.","title_case":false,"type":"str"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from crewai import Agent  # type: ignore\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, DictInput, HandleInput, MessageTextInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MessageTextInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MessageTextInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MessageTextInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"goal":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"Search for information about the User's query and answer as best as you can","name":"goal","display_name":"Goal","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The objective of the agent.","title_case":false,"type":"str"},"kwargs":{"trace_as_input":true,"list":true,"required":false,"placeholder":"","show":true,"value":{},"name":"kwargs","display_name":"kwargs","advanced":true,"dynamic":false,"info":"kwargs of agent.","title_case":false,"type":"dict"},"memory":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":true,"name":"memory","display_name":"Memory","advanced":true,"dynamic":false,"info":"Whether the agent should have memory or not","title_case":false,"type":"bool"},"role":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"Librarian","name":"role","display_name":"Role","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The role of the agent.","title_case":false,"type":"str"},"verbose":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"verbose","display_name":"Verbose","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool"}},"description":"Represents an agent of CrewAI.","icon":"CrewAI","base_classes":["Agent"],"display_name":"CrewAI Agent","documentation":"https://docs.crewai.com/how-to/LLM-Connections/","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Agent"],"selected":"Agent","name":"output","display_name":"Agent","method":"build_output","value":"__UNDEFINED__","cache":true}],"field_order":["role","goal","backstory","tools","llm","memory","verbose","allow_delegation","allow_code_execution","kwargs"],"beta":false,"edited":false},"id":"CrewAIAgentComponent-XU5MB"},"selected":false,"width":384,"height":665,"positionAbsolute":{"x":-458.5916982102759,"y":446.46227931983833},"dragging":false},{"id":"RetrieverTool-EDIkE","type":"genericNode","position":{"x":-1068.5911571542506,"y":204.83293489031553},"data":{"type":"RetrieverTool","node":{"template":{"_type":"CustomComponent","retriever":{"type":"BaseRetriever","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"retriever","display_name":"Retriever","advanced":false,"input_types":["Retriever"],"dynamic":false,"info":"Retriever to interact with","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain.tools.retriever import create_retriever_tool\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import BaseRetriever, Tool\n\n\nclass RetrieverToolComponent(CustomComponent):\n    display_name = \"RetrieverTool\"\n    description = \"Tool for interacting with retriever\"\n    name = \"RetrieverTool\"\n\n    def build_config(self):\n        return {\n            \"retriever\": {\n                \"display_name\": \"Retriever\",\n                \"info\": \"Retriever to interact with\",\n                \"input_types\": [\"Retriever\"],\n            },\n            \"name\": {\"display_name\": \"Name\", \"info\": \"Name of the tool\"},\n            \"description\": {\"display_name\": \"Description\", \"info\": \"Description of the tool\"},\n        }\n\n    def build(\n        self,\n        retriever: BaseRetriever,\n        name: str,\n        description: str,\n    ) -> Tool:\n        return create_retriever_tool(\n            retriever=retriever,\n            name=name,\n            description=description,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"description":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"description","display_name":"Description","advanced":false,"dynamic":false,"info":"Description of the tool","load_from_db":false,"title_case":false,"input_types":["Text"]},"name":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"name","display_name":"Name","advanced":false,"dynamic":false,"info":"Name of the tool","load_from_db":false,"title_case":false,"input_types":["Text"]}},"description":"Tool for interacting with retriever","base_classes":["BaseTool","Generic","object","Runnable","RunnableSerializable","Serializable","Tool"],"display_name":"RetrieverTool","documentation":"","custom_fields":{"retriever":null,"name":null,"description":null},"output_types":["Tool"],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Tool"],"selected":"Tool","name":"tool","hidden":null,"display_name":"Tool","method":null,"value":"__UNDEFINED__","cache":true}],"field_order":[],"beta":false,"edited":true},"id":"RetrieverTool-EDIkE","description":"Tool for interacting with retriever","display_name":"RetrieverTool"},"selected":false,"width":384,"height":451,"positionAbsolute":{"x":-1068.5911571542506,"y":204.83293489031553},"dragging":false},{"id":"Chroma-rMIN9","type":"genericNode","position":{"x":-1770.5092158203793,"y":-95.1804288944008},"data":{"type":"Chroma","node":{"template":{"_type":"Component","embedding":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"embedding","display_name":"Embedding","advanced":false,"input_types":["Embeddings"],"dynamic":false,"info":"","title_case":false,"type":"other"},"ingest_data":{"trace_as_input":true,"trace_as_metadata":true,"list":true,"required":false,"placeholder":"","show":true,"value":"","name":"ingest_data","display_name":"Ingest Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other"},"allow_duplicates":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"allow_duplicates","display_name":"Allow Duplicates","advanced":true,"dynamic":false,"info":"If false, will not add documents that are already in the Vector Store.","title_case":false,"type":"bool"},"chroma_server_cors_allow_origins":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"chroma_server_cors_allow_origins","display_name":"Server CORS Allow Origins","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str"},"chroma_server_grpc_port":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"chroma_server_grpc_port","display_name":"Server gRPC Port","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"int"},"chroma_server_host":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"chroma_server_host","display_name":"Server Host","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str"},"chroma_server_http_port":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"chroma_server_http_port","display_name":"Server HTTP Port","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"int"},"chroma_server_ssl_enabled":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"chroma_server_ssl_enabled","display_name":"Server SSL Enabled","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from copy import deepcopy\nfrom typing import TYPE_CHECKING\n\nfrom chromadb.config import Settings\nfrom langchain_chroma.vectorstores import Chroma\nfrom loguru import logger\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.base.vectorstores.utils import chroma_collection_to_data\nfrom langflow.io import BoolInput, DataInput, DropdownInput, HandleInput, IntInput, StrInput, MultilineInput\nfrom langflow.schema import Data\n\nif TYPE_CHECKING:\n    from langchain_chroma import Chroma\n\n\nclass ChromaVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    Chroma Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"Chroma DB\"\n    description: str = \"Chroma Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/integrations/vectorstores/chroma\"\n    name = \"Chroma\"\n    icon = \"Chroma\"\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            value=\"langflow\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        StrInput(\n            name=\"chroma_server_cors_allow_origins\",\n            display_name=\"Server CORS Allow Origins\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"chroma_server_host\",\n            display_name=\"Server Host\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_http_port\",\n            display_name=\"Server HTTP Port\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_grpc_port\",\n            display_name=\"Server gRPC Port\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"chroma_server_ssl_enabled\",\n            display_name=\"Server SSL Enabled\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"allow_duplicates\",\n            display_name=\"Allow Duplicates\",\n            advanced=True,\n            info=\"If false, will not add documents that are already in the Vector Store.\",\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"Similarity\", \"MMR\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=10,\n        ),\n        IntInput(\n            name=\"limit\",\n            display_name=\"Limit\",\n            advanced=True,\n            info=\"Limit the number of records to compare when Allow Duplicates is False.\",\n        ),\n    ]\n\n    def build_vector_store(self) -> Chroma:\n        \"\"\"\n        Builds the Chroma object.\n        \"\"\"\n        try:\n            from chromadb import Client\n            from langchain_chroma import Chroma\n        except ImportError:\n            raise ImportError(\n                \"Could not import Chroma integration package. \" \"Please install it with `pip install langchain-chroma`.\"\n            )\n        # Chroma settings\n        chroma_settings = None\n        client = None\n        if self.chroma_server_host:\n            chroma_settings = Settings(\n                chroma_server_cors_allow_origins=self.chroma_server_cors_allow_origins or [],\n                chroma_server_host=self.chroma_server_host,\n                chroma_server_http_port=self.chroma_server_http_port or None,\n                chroma_server_grpc_port=self.chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=self.chroma_server_ssl_enabled,\n            )\n            client = Client(settings=chroma_settings)\n\n        # Check persist_directory and expand it if it is a relative path\n        if self.persist_directory is not None:\n            persist_directory = self.resolve_path(self.persist_directory)\n        else:\n            persist_directory = None\n\n        chroma = Chroma(\n            persist_directory=persist_directory,\n            client=client,\n            embedding_function=self.embedding,\n            collection_name=self.collection_name,\n        )\n\n        self._add_documents_to_vector_store(chroma)\n        self.status = chroma_collection_to_data(chroma.get(limit=self.limit))\n        return chroma\n\n    def _add_documents_to_vector_store(self, vector_store: \"Chroma\") -> None:\n        \"\"\"\n        Adds documents to the Vector Store.\n        \"\"\"\n        if not self.ingest_data:\n            self.status = \"\"\n            return\n\n        _stored_documents_without_id = []\n        if self.allow_duplicates:\n            stored_data = []\n        else:\n            stored_data = chroma_collection_to_data(vector_store.get(self.limit))\n            for value in deepcopy(stored_data):\n                del value.id\n                _stored_documents_without_id.append(value)\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                if _input not in _stored_documents_without_id:\n                    documents.append(_input.to_lc_document())\n            else:\n                raise ValueError(\"Vector Store Inputs must be Data objects.\")\n\n        if documents and self.embedding is not None:\n            logger.debug(f\"Adding {len(documents)} documents to the Vector Store.\")\n            vector_store.add_documents(documents)\n        else:\n            logger.debug(\"No documents to add to the Vector Store.\")\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_name":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"langflow","name":"collection_name","display_name":"Collection Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str"},"limit":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"limit","display_name":"Limit","advanced":true,"dynamic":false,"info":"Limit the number of records to compare when Allow Duplicates is False.","title_case":false,"type":"int"},"number_of_results":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":10,"name":"number_of_results","display_name":"Number of Results","advanced":true,"dynamic":false,"info":"Number of results to return.","title_case":false,"type":"int"},"persist_directory":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"persist_directory","display_name":"Persist Directory","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str"},"search_query":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"search_query","display_name":"Search Query","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"search_type":{"trace_as_metadata":true,"options":["Similarity","MMR"],"required":false,"placeholder":"","show":true,"value":"Similarity","name":"search_type","display_name":"Search Type","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str"}},"description":"Chroma Vector Store with search capabilities","icon":"Chroma","base_classes":["Data","Retriever","VectorStore"],"display_name":"Chroma DB","documentation":"https://python.langchain.com/docs/integrations/vectorstores/chroma","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Retriever"],"selected":"Retriever","name":"base_retriever","display_name":"Retriever","method":"build_base_retriever","value":"__UNDEFINED__","cache":true},{"types":["Data"],"selected":"Data","name":"search_results","display_name":"Search Results","method":"search_documents","value":"__UNDEFINED__","cache":true},{"types":["VectorStore"],"selected":"VectorStore","name":"vector_store","display_name":"Vector Store","method":"cast_vector_store","value":"__UNDEFINED__","cache":true}],"field_order":["collection_name","persist_directory","search_query","ingest_data","embedding","chroma_server_cors_allow_origins","chroma_server_host","chroma_server_http_port","chroma_server_grpc_port","chroma_server_ssl_enabled","allow_duplicates","search_type","number_of_results","limit"],"beta":false,"edited":false},"id":"Chroma-rMIN9"},"selected":false,"width":384,"height":673,"positionAbsolute":{"x":-1770.5092158203793,"y":-95.1804288944008},"dragging":false}],"edges":[{"source":"HierarchicalCrewComponent-JNKGT","sourceHandle":"{œdataTypeœ:œHierarchicalCrewComponentœ,œidœ:œHierarchicalCrewComponent-JNKGTœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}","target":"ChatOutput-IACYe","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-IACYeœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-IACYe","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"HierarchicalCrewComponent","id":"HierarchicalCrewComponent-JNKGT","name":"output","output_types":["Message"]}},"id":"reactflow__edge-HierarchicalCrewComponent-JNKGT{œdataTypeœ:œHierarchicalCrewComponentœ,œidœ:œHierarchicalCrewComponent-JNKGTœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-IACYe{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-IACYeœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","selected":false,"className":""},{"source":"HierarchicalTaskComponent-vvJXu","sourceHandle":"{œdataTypeœ:œHierarchicalTaskComponentœ,œidœ:œHierarchicalTaskComponent-vvJXuœ,œnameœ:œtask_outputœ,œoutput_typesœ:[œHierarchicalTaskœ]}","target":"HierarchicalCrewComponent-JNKGT","targetHandle":"{œfieldNameœ:œtasksœ,œidœ:œHierarchicalCrewComponent-JNKGTœ,œinputTypesœ:[œHierarchicalTaskœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"tasks","id":"HierarchicalCrewComponent-JNKGT","inputTypes":["HierarchicalTask"],"type":"other"},"sourceHandle":{"dataType":"HierarchicalTaskComponent","id":"HierarchicalTaskComponent-vvJXu","name":"task_output","output_types":["HierarchicalTask"]}},"id":"reactflow__edge-HierarchicalTaskComponent-vvJXu{œdataTypeœ:œHierarchicalTaskComponentœ,œidœ:œHierarchicalTaskComponent-vvJXuœ,œnameœ:œtask_outputœ,œoutput_typesœ:[œHierarchicalTaskœ]}-HierarchicalCrewComponent-JNKGT{œfieldNameœ:œtasksœ,œidœ:œHierarchicalCrewComponent-JNKGTœ,œinputTypesœ:[œHierarchicalTaskœ],œtypeœ:œotherœ}","selected":false,"className":""},{"source":"CrewAIAgentComponent-XU5MB","sourceHandle":"{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-XU5MBœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}","target":"HierarchicalCrewComponent-JNKGT","targetHandle":"{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-JNKGTœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"agents","id":"HierarchicalCrewComponent-JNKGT","inputTypes":["Agent"],"type":"other"},"sourceHandle":{"dataType":"CrewAIAgentComponent","id":"CrewAIAgentComponent-XU5MB","name":"output","output_types":["Agent"]}},"id":"reactflow__edge-CrewAIAgentComponent-XU5MB{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-XU5MBœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}-HierarchicalCrewComponent-JNKGT{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-JNKGTœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}","className":""},{"source":"OpenAIModel-xoZ41","sourceHandle":"{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-xoZ41œ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}","target":"CrewAIAgentComponent-XU5MB","targetHandle":"{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-XU5MBœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"llm","id":"CrewAIAgentComponent-XU5MB","inputTypes":["LanguageModel"],"type":"other"},"sourceHandle":{"dataType":"OpenAIModel","id":"OpenAIModel-xoZ41","name":"model_output","output_types":["LanguageModel"]}},"id":"reactflow__edge-OpenAIModel-xoZ41{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-xoZ41œ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-CrewAIAgentComponent-XU5MB{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-XU5MBœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}","className":""},{"source":"RetrieverTool-EDIkE","sourceHandle":"{œdataTypeœ:œRetrieverToolœ,œidœ:œRetrieverTool-EDIkEœ,œnameœ:œtoolœ,œoutput_typesœ:[œToolœ]}","target":"CrewAIAgentComponent-XU5MB","targetHandle":"{œfieldNameœ:œtoolsœ,œidœ:œCrewAIAgentComponent-XU5MBœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"tools","id":"CrewAIAgentComponent-XU5MB","inputTypes":["Tool"],"type":"other"},"sourceHandle":{"dataType":"RetrieverTool","id":"RetrieverTool-EDIkE","name":"tool","output_types":["Tool"]}},"id":"reactflow__edge-RetrieverTool-EDIkE{œdataTypeœ:œRetrieverToolœ,œidœ:œRetrieverTool-EDIkEœ,œnameœ:œtoolœ,œoutput_typesœ:[œToolœ]}-CrewAIAgentComponent-XU5MB{œfieldNameœ:œtoolsœ,œidœ:œCrewAIAgentComponent-XU5MBœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}","className":""},{"source":"Chroma-rMIN9","sourceHandle":"{œdataTypeœ:œChromaœ,œidœ:œChroma-rMIN9œ,œnameœ:œbase_retrieverœ,œoutput_typesœ:[œRetrieverœ]}","target":"RetrieverTool-EDIkE","targetHandle":"{œfieldNameœ:œretrieverœ,œidœ:œRetrieverTool-EDIkEœ,œinputTypesœ:[œRetrieverœ],œtypeœ:œBaseRetrieverœ}","data":{"targetHandle":{"fieldName":"retriever","id":"RetrieverTool-EDIkE","inputTypes":["Retriever"],"type":"BaseRetriever"},"sourceHandle":{"dataType":"Chroma","id":"Chroma-rMIN9","name":"base_retriever","output_types":["Retriever"]}},"id":"reactflow__edge-Chroma-rMIN9{œdataTypeœ:œChromaœ,œidœ:œChroma-rMIN9œ,œnameœ:œbase_retrieverœ,œoutput_typesœ:[œRetrieverœ]}-RetrieverTool-EDIkE{œfieldNameœ:œretrieverœ,œidœ:œRetrieverTool-EDIkEœ,œinputTypesœ:[œRetrieverœ],œtypeœ:œBaseRetrieverœ}","className":""}],"viewport":{"x":678.2720210526091,"y":260.4906468031912,"zoom":0.3405645086601322}},"description":"Crafting Dialogues that Drive Business Success.","name":"Hierarchical Tasks Agent","last_tested_version":"1.0.9","endpoint_name":null,"is_component":false}